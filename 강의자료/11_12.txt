RNN(Recurrent Neural Networks - 순환 신경망)
-> 순차적(주식, 날씨 등등) - 시간에 따라 순차적으로 얻을 수 있는 데이터
-> TimeSeries (시계열)
-> 언어(문법에 따라 순차적인 단어가 들어와야 한다)
-> ex) 나는 먹었다 밥을(x), 나는 밥을 먹었다(o)

LSTM
-> RNN은 관련 정보와 그 정보를 사용하는 지점 사이 거리가 멀 경우 역전파시 그래디언트가 점차 줄어 학습능력이 크게 저하되는 것으로 알려져 있습니다. 
-> 이를 vanishing gradient problem이라고 합니다.
-> 이 문제를 극복하기 위해서 고안된 것이 바로 LSTM입니다. 
