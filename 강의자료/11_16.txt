파이썬 공부 틈틈히 하기

---------------------------------------------------------------------
첫번째 주 배웠던 개념 정리

DNN - Deep의 개념 
-> Node, Layer (신경망)
-> y = wx + b
-> w는 모든 layer에 존재한다
-> 최적의 weight를 구하기 위해 최소의 loss(0의 근사치로)
-> optimizer 'adam', 평균 85%

summary를 통해 parameter를 계산
-> 3x4 = 16, 4x3 = 15
-> bias의 존재 (1)

함수형 모델
-> 모델끼리 만들어서 연결을해서 묶어준다(앙상블)
-> concatenate (대문자, 소문자 문법 다름 주의!)

LSTM
-> 순차 데이터(ex - 시간순서가 있는 데이터)
-> TimeSeries(시계열)
-> 행, 열, 몇개씩 자르는지
-> input_shape(행무시! = 열, 자르는 갯수)

CNN
-> 차원 4차원
-> 이미지의 갯수 x 가로 x 세로 x 픽셀
-> 행무시! = 가로 x 세로 x 픽셀(3차원)

LSTM을 두개로 여러개로 묶을 경우
-> 데이터에 따라 다르다
-> 좋다 - 정답x,  안좋다 - 정답x
-> 돌려보고 확인해야 한다
-> return_sequence(차원을 넘겨줄때 사용)

early_stopping
-> monitor = 'loss'
-> patience = 100
-> mode = 'min'

history
-> hist = fit
-> 시각화
-> matplotlib
-> tensorboard

model save, load

데이터 전처리
-> scaler(minmax, standard, robust, maxabs)
-> 85% Data 전처리
-> standard_scaler - 가운데지점이 0

ex) 101, 102, 103, 104, 105, 107, 299 라는 데이터로 결과를 추출한다고 가정
-> 299는 이상한 데이터이다
-> 이상치라고 한다
-> 이상치 제거
-> 깔끔한 데이터셋을 구성할 수 있다
-> but 299라는 데이터가 존재하지만 이상치라고 제거했을 경우에는 데이터 조작이 되기 때문에 주의해야 한다

외우기!
      ㅣ      X      ㅣ    Y    ㅣ
---------------------------------
train ㅣfit/transformㅣ    X    ㅣ
test  ㅣ transform   ㅣ    X    ㅣ
val   ㅣ transform   ㅣ    X    ㅣ
pred  ㅣ transform   ㅣ    X    ㅣ

ai developer 지향, data scientist 지양

---------------------------------------------------------------------

