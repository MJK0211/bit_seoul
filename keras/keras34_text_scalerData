# #1. 데이터
# x = array([[1,2,3], [2,3,4], [3,4,5], [4,5,6], 
#            [5,6,7], [6,7,8], [7,8,9], [8,9,10],
#            [9,10,11], [10,11,12], 
#            [2000,3000,4000], [3000,4000,5000], [4000,5000,6000],
#            [100,200,300]]) # (14,3)

# MinMax - x - 최대/최소값이 각각 1, 0이 되도록 스케일링
# 모든 feature 값이 0~1사이에 있도록 데이터를 재조정한다. 다만 이상치가 있는 경우 변환된 값이 매우 좁은 범위로 압축될 수 있다.
# 결과값
# [[0.00000000e+00 0.00000000e+00 0.00000000e+00]  -> 1은 0
#  [2.50062516e-04 2.00080032e-04 1.66750042e-04]  -> 열마다 데이터 최대값이 다름 1번째 열은 4000, 3번째 열은 6000
#  [5.00125031e-04 4.00160064e-04 3.33500083e-04]
#  [7.50187547e-04 6.00240096e-04 5.00250125e-04]
#  [1.00025006e-03 8.00320128e-04 6.67000167e-04]
#  [1.25031258e-03 1.00040016e-03 8.33750208e-04]
#  [1.50037509e-03 1.20048019e-03 1.00050025e-03]
#  [1.75043761e-03 1.40056022e-03 1.16725029e-03]
#  [2.00050013e-03 1.60064026e-03 1.33400033e-03]
#  [2.25056264e-03 1.80072029e-03 1.50075038e-03]
#  [4.99874969e-01 5.99839936e-01 6.66499917e-01]
#  [7.49937484e-01 7.99919968e-01 8.33249958e-01]
#  [1.00000000e+00 1.00000000e+00 1.00000000e+00]  -> 열기준 4000, 5000, 6000짜리가 1 (최대값이기 때문)
#  [2.47561890e-02 3.96158463e-02 4.95247624e-02]] -> 전체 데이터는 0~1사이의 값으로 전처리 된것을 볼 수 있다

# StandardScaler - x - 기본 스케일. 평균과 표준편차 사용
# 평균을 제거하고 데이터를 단위 분산으로 조정한다. 그러나 이상치가 있다면 평균과 표준편차에 영향을 미쳐 변환된 데이터의 확산은 매우 달라지게 된다.
# 결과값
#  [-0.50836632 -0.52112564 -0.52765244]
#  [-0.50758653 -0.52052876 -0.52717022]
#  [-0.50680674 -0.51993187 -0.526688  ]
#  [-0.50602695 -0.51933498 -0.52620578]
#  [-0.50524716 -0.51873809 -0.52572356]
#  [-0.50446737 -0.51814121 -0.52524134]
#  [-0.50368759 -0.51754432 -0.52475912]
#  [-0.5029078  -0.51694743 -0.5242769 ]
#  [-0.50212801 -0.51635054 -0.52379468]
#  [ 1.04965084  1.26774696  1.39930025]
#  [ 1.82943921  1.86463471  1.88152064]
#  [ 2.60922758  2.46152247  2.36374103]
#  [-0.43194706 -0.40353876 -0.38491521]]

# RobustScaler - x -중앙값(median)과 IQR(interquartile range) 사용. 아웃라이어의 영향을 최소화
# 아웃라이어의 영향을 최소화한 기법이다. 중앙값(median)과 IQR(interquartile range)을 사용하기 때문에 StandardScaler와 비교해보면 표준화 후 동일한 값을 더 넓게 분포 시키고 있음을 확인 할 수 있다.
# 결과값
# [[-8.87372014e-02 -4.40677966e-02 -2.93122886e-02]
#  [-7.50853242e-02 -3.72881356e-02 -2.48027057e-02]
#  [-6.14334471e-02 -3.05084746e-02 -2.02931229e-02]
#  [-4.77815700e-02 -2.37288136e-02 -1.57835400e-02]
#  [-3.41296928e-02 -1.69491525e-02 -1.12739572e-02]
#  [-2.04778157e-02 -1.01694915e-02 -6.76437430e-03]
#  [-6.82593857e-03 -3.38983051e-03 -2.25479143e-03]
#  [ 6.82593857e-03  3.38983051e-03  2.25479143e-03]
#  [ 2.04778157e-02  1.01694915e-02  6.76437430e-03]
#  [ 3.41296928e-02  1.69491525e-02  1.12739572e-02]
#  [ 2.72013652e+01  2.02813559e+01  1.79954904e+01]
#  [ 4.08532423e+01  2.70610169e+01  2.25050733e+01]
#  [ 5.45051195e+01  3.38406780e+01  2.70146561e+01]
#  [ 1.26279863e+00  1.29830508e+00  1.31003382e+00]]

# MaxAbsScaler - x - 최대절대값과 0이 각각 1, 0이 되도록 스케일링
# 절대값이 0~1사이에 매핑되도록 한다. 즉 -1~1 사이로 재조정한다. 양수 데이터로만 구성된 특징 데이터셋에서는 MinMaxScaler와 유사하게 동작하며, 큰 이상치에 민감할 수 있다.
# 결과값
# [[2.50000000e-04 4.00000000e-04 5.00000000e-04]
#  [5.00000000e-04 6.00000000e-04 6.66666667e-04]
#  [7.50000000e-04 8.00000000e-04 8.33333333e-04]
#  [1.00000000e-03 1.00000000e-03 1.00000000e-03]
#  [1.25000000e-03 1.20000000e-03 1.16666667e-03]
#  [1.50000000e-03 1.40000000e-03 1.33333333e-03]
#  [1.75000000e-03 1.60000000e-03 1.50000000e-03]
#  [2.00000000e-03 1.80000000e-03 1.66666667e-03]
#  [2.25000000e-03 2.00000000e-03 1.83333333e-03]
#  [2.50000000e-03 2.20000000e-03 2.00000000e-03]
#  [5.00000000e-01 6.00000000e-01 6.66666667e-01]
#  [7.50000000e-01 8.00000000e-01 8.33333333e-01]
#  [1.00000000e+00 1.00000000e+00 1.00000000e+00]
#  [2.50000000e-02 4.00000000e-02 5.00000000e-02]]