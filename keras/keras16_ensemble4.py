#tran_test_split에서 추가하지 않는다
#Input 1개 Output 3개

#1. 데이터
import numpy as np

x1 = np.array([range(1,101), range(711,811), range(100)]) #100개의 데이터 3개 - 100행 3열 input_shape (3,)

y1 = np.array([range(101,201), range(311,411), range(100)]) #output 3
y2 = np.array([range(501,601), range(431,531), range(100,200)])
y3 = np.array([range(501,601), range(431,531), range(100,200)])

x1 = np.transpose(x1)

y1 = np.transpose(y1)
y2 = np.transpose(y2)
y3 = np.transpose(y3)

from sklearn.model_selection import train_test_split
x1_train, x1_test = train_test_split(x1, train_size=0.7)
y1_train, y1_test, y2_train, y2_test, y3_train, y3_test = train_test_split(y1, y2, y3, train_size=0.7)


#2. 모델구성
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, Input, concatenate, Concatenate #concatenate 추가

#2_1 모델1
input1 = Input(shape=(3,)) #input1 layer 구성
dense1_1 = Dense(10, activation='relu', name='king1')(input1) #model.summary() dense부분에 가독성을 위해
dense1_2 = Dense(7, activation='relu', name='king2')(dense1_1) 
dense1_3 = Dense(5, activation='relu', name='king3')(dense1_2)
output = Dense(3, name='king4')(dense1_3)

#output 모델 구성 (분기-나눔)
output1_1 = Dense(30)(output)
output1_2 = Dense(7)(output1_1)
output1_3 = Dense(3)(output1_1)

output2 = Dense(15)(output)
output2_1 = Dense(14)(output2)
output2_2 = Dense(11)(output2_1)
output2_3 = Dense(3)(output2_2)

output3 = Dense(15)(output)
output3_1 = Dense(14)(output3)
output3_2 = Dense(11)(output3_1)
output3_3 = Dense(3)(output3_2)



#모델 정의
model = Model(inputs=input1, outputs=[output1_3, output2_3, output3_3])

#3. 컴파일,훈련

model.compile(loss='mse', optimizer='adam', metrics=['mse'])
model.fit(x1_train, [y1_train, y2_train, y3_train], epochs=100, batch_size=1, validation_split=0.25, verbose=1)

#4. 평가, 예측

result = model.evaluate(x1_test, [y1_test, y2_test, y3_test], batch_size=1)

print(result)

y1_pred, y2_pred, y3_pred = model.predict(x1_test)

print("y_pred : \n", y1_pred, y2_pred, y3_pred)

from sklearn.metrics import mean_absolute_error
def RMSE(y1_test, y2_test, y3_test, y1_pred, y2_pred, y3_pred):
    return np.sqrt((mean_absolute_error(y1_test, y1_pred)+mean_absolute_error(y2_test, y2_pred)+mean_absolute_error(y3_test, y3_pred))/3)
print("RMSE : ", RMSE(y1_test, y2_test, y3_test, y1_pred, y2_pred, y3_pred))

from sklearn.metrics import r2_score
r2 = (r2_score(y1_test, y1_pred) + r2_score(y2_test, y2_pred) + r2_score(y3_test, y3_pred))/3
print("R2 : ", r2)

# 결과값
# y_pred : 
#  [[146.63556  357.1835    45.852825]
#  [146.40193  357.32208   45.84699 ]
#  [146.41753  357.31287   45.847385]
#  [146.37857  357.33597   45.84641 ]
#  [146.30069  357.3821    45.84447 ]
#  [146.37077  357.34058   45.846226]
#  [146.05147  357.52994   45.838245]
#  [146.51094  357.2574    45.84972 ]
#  [146.56546  357.22507   45.851078]
#  [146.44864  357.29434   45.848156]
#  [146.46425  357.28513   45.848553]
#  [146.53432  357.24356   45.850292]
#  [146.45642  357.2897    45.84837 ]
#  [146.36299  357.34518   45.846027]
#  [146.28511  357.39133   45.84408 ]
#  [146.44087  357.29895   45.84795 ]
#  [146.07483  357.51605   45.83884 ]
#  [146.33961  357.35904   45.845432]
#  [146.65892  357.16965   45.85342 ]
#  [146.61998  357.19272   45.85245 ]
#  [146.35518  357.34976   45.84583 ]
#  [146.26953  357.4006    45.843693]
#  [146.1371   357.4791    45.840374]
#  [146.0982   357.50223   45.839413]
#  [146.64336  357.17886   45.85303 ]
#  [145.97362  357.57617   45.836308]
#  [146.58104  357.21582   45.851475]
#  [146.58884  357.2112    45.851665]
#  [146.18387  357.45145   45.841557]
#  [146.32405  357.36826   45.84505 ]] 
# [[551.36615 478.82785 141.25182]
#  [549.8419  477.93112 140.8398 ]
#  [549.94354 477.99088 140.86726]
#  [549.68945 477.8414  140.7986 ]
#  [549.1813  477.54245 140.66122]
#  [549.6386  477.8115  140.78485]
#  [547.5555  476.58603 140.22174]
#  [550.5532  478.34952 141.0321 ]
#  [550.9089  478.55875 141.12825]
#  [550.1467  478.11038 140.92223]
#  [550.2483  478.17014 140.94965]
#  [550.70557 478.43918 141.07327]
#  [550.19745 478.1403  140.93599]
#  [549.5879  477.78165 140.77115]
#  [549.0797  477.4827  140.63376]
#  [550.0958  478.08047 140.90848]
#  [547.70776 476.6757  140.26294]
#  [549.4354  477.692   140.72995]
#  [551.5185  478.91742 141.29301]
#  [551.26447 478.76797 141.22437]
#  [549.537   477.75174 140.75737]
#  [548.9781  477.42294 140.60632]
#  [548.1143  476.9148  140.37282]
#  [547.86035 476.76535 140.30417]
#  [551.4169  478.85767 141.26553]
#  [547.0475  476.2872  140.08444]
#  [551.01044 478.61853 141.15565]
#  [551.0612  478.64847 141.1694 ]
#  [548.41925 477.09415 140.45523]
#  [549.33374 477.63217 140.70247]] 
# [[550.482   478.1962  140.34407]
#  [551.46027 478.5606  140.52032]
#  [551.395   478.53625 140.5086 ]
#  [551.55804 478.597   140.538  ]
#  [551.88416 478.7184  140.59671]
#  [551.59064 478.60916 140.54388]
#  [552.9276  479.10724 140.78482]
#  [551.00366 478.39047 140.43808]
#  [550.7753  478.3054  140.39691]
#  [551.2645  478.48767 140.48508]
#  [551.1994  478.46338 140.47333]
#  [550.9059  478.35403 140.42044]
#  [551.2319  478.47543 140.47922]
#  [551.6232  478.62128 140.54974]
#  [551.9493  478.74274 140.60852]
#  [551.29724 478.49982 140.49095]
#  [552.8298  479.07074 140.76714]
#  [551.72107 478.6577  140.56734]
#  [550.3842  478.15967 140.32642]
#  [550.5472  478.22037 140.35579]
#  [551.6558  478.63342 140.5556 ]
#  [552.0146  478.7671  140.62027]
#  [552.5689  478.9735  140.72018]
#  [552.73193 479.03427 140.74954]
#  [550.44934 478.18396 140.33815]
#  [553.2538  479.22876 140.84364]
#  [550.71027 478.28116 140.38516]
#  [550.6777  478.26898 140.37929]
#  [552.3732  478.90067 140.6849 ]
#  [551.7863  478.68207 140.57913]]
# RMSE :  4.524987887246671
# R2 :  -0.028936601390401107